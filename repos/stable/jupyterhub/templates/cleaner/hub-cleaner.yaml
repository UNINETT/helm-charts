apiVersion: batch/v1
kind: Job
metadata:
  name: "{{.Release.Name}}-hub-pod"
  labels:
    heritage: {{.Release.Service | quote }}
    release: {{.Release.Name | quote }}
    chart: "{{.Chart.Name}}-{{.Chart.Version}}"
    group: {{ .Release.Name }}-jupyterhub
  annotations:
    # This is what defines this resource as a hook.
    # We need to delete the hub pod due to proxy token issue
    "helm.sh/hook": post-upgrade
    "helm.sh/hook-weight": "2"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  template:
    metadata:
      name: "{{.Release.Name}}-hub-pod"
      labels:
        heritage: {{.Release.Service | quote }}
        release: {{.Release.Name | quote }}
        chart: "{{.Chart.Name}}-{{.Chart.Version}}"
        group: {{ .Release.Name }}-jupyterhub
    spec:
      restartPolicy: Never
      serviceAccountName: {{.Release.Name}}-pod-cleaner
      containers:
      - name: pod-clean-job
        image: "gurvin/kubectl:1.10.5"
        imagePullPolicy: IfNotPresent
        env:
        - name: RELEASE
          value: {{.Release.Name}}
        - name: NAMESPACE
          value: {{ .Release.Namespace }}
        command:
          - /bin/sh
        args:
          - -c
          - -x
          - "kubectl --namespace=${NAMESPACE} --selector=release=${RELEASE},component=hub delete pod"


{{ if ne .Values.persistentStorage.existingClaim "" }}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{.Release.Name}}-cleaner"
  labels:
    heritage: {{.Release.Service | quote }}
    release: {{.Release.Name | quote }}
    chart: "{{.Chart.Name}}-{{.Chart.Version}}"
  annotations:
    "helm.sh/hook": post-delete
    "helm.sh/hook-weight": "2"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  template:
    metadata:
      name: "{{.Release.Name}}-cleaner"
      labels:
        heritage: {{.Release.Service | quote }}
        release: {{.Release.Name | quote }}
        chart: "{{.Chart.Name}}-{{.Chart.Version}}"
    spec:
      volumes:
      - name: {{ .Values.persistentStorage.existingClaimName }}
        persistentVolumeClaim:
          claimName: {{ .Values.persistentStorage.existingClaim }}
      restartPolicy: Never
      containers:
      - name: cleaner-job
        image: "alpine:3.8"
        imagePullPolicy: Always
        command:
          - /bin/sh
        args:
          - -c
          - -x
          - "rm -rf /mnt/{{ .Values.persistentStorage.existingClaimName }}/.tools/{{ template "fullname" . }}-hub"
        volumeMounts:
        - name: {{ .Values.persistentStorage.existingClaimName }}
          mountPath: /mnt/{{ .Values.persistentStorage.existingClaimName }}
{{ end }}
