{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "25e6ceea-d40d-43e7-aa40-d9aabfbb1e2d"
   },
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png)\n",
    "![Python Logo](http://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/R_logo.svg/200px-R_logo.svg.png)\n",
    "\n",
    "# Welcome to Apache Spark with R\n",
    "\n",
    "> Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming. \n",
    "- http://spark.apache.org/\n",
    "\n",
    "In this notebook we will introduce basic concepts about SparkSQL with R that you can find in the [SparkR documentation](http://spark.apache.org/docs/latest/sparkr.html), applied to the example people dataset. We will do two things, read data into a SparkSQL data frame, and have a quick look at the schema and what we have read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2b27963a-2fdc-43a2-9215-1e4144024fa1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'SparkR'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var, window\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    as.data.frame, colnames, colnames<-, drop, endsWith, intersect,\n",
      "    rank, rbind, sample, startsWith, subset, summary, transform, union\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /usr/local/spark/bin/spark-submit   sparkr-shell /tmp/Rtmp3mWazA/backend_port9e113cc0dc \n"
     ]
    }
   ],
   "source": [
    "##Creating a SparkSQL context and loading dataÂ¶\n",
    "library(SparkR)\n",
    "sc <- sparkR.session(sparkConfig = list(spark.app.name = \"R Spark Test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b621ce6e-4c50-4330-81b7-68ff267d1d3e"
   },
   "outputs": [],
   "source": [
    "people <- read.df(\"/opt/datasets/people.json\", \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "8796dece-b38b-43f9-bfe7-7915330329e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "printSchema(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "417bb495-cdc5-4189-bc09-4d771d804c65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>age</th><th scope=col>name</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>NA     </td><td>Michael</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>30  </td><td>Andy</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>19    </td><td>Justin</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & age & name\\\\\n",
       "\\hline\n",
       "\t1 & NA      & Michael\\\\\n",
       "\t2 & 30   & Andy\\\\\n",
       "\t3 & 19     & Justin\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  age    name\n",
       "1  NA Michael\n",
       "2  30    Andy\n",
       "3  19  Justin"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e45d24db-c3c2-4f12-a22f-5187da097497"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>age</th><th scope=col>name</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>30  </td><td>Andy</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & age & name\\\\\n",
       "\\hline\n",
       "\t1 & 30   & Andy\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  age name\n",
       "1  30 Andy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(filter(people, people$age > 19))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
